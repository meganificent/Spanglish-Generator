{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project",
      "provenance": [],
      "collapsed_sections": [
        "Ne9tmi-0P7I2",
        "8IQ2NE-KQmvj",
        "f4yH_HBz0BZf",
        "t-kpFQz7J6uA",
        "V7iAKLsWdED2",
        "K0AR8EKfCHbP"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meganificent/Language-Style-Transfer/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ths7y9Z4OYNM"
      },
      "source": [
        "# Spanglish Machine Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDqMPNZoRM-9",
        "outputId": "1ed4590c-b743-44ca-93e6-f064cbae4d21"
      },
      "source": [
        "spanglishMachine(\"We have finally completed this laborious project for you\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - Posessive Nouns pt 1: [('We', 'PRP'), ('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('laborious', 'JJ'), ('project', 'NN'), ('for', 'IN'), ('you', 'PRP')]\n",
            "2 - Long Sentence Verb+Noun: [('We', 'PRP'), ('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('laborious', 'JJ'), ('project', 'NN'), ('for', 'IN'), ('you', 'PRP')]\n",
            "3 - Remove 'To' and Swap PRP: [('We', 'PRP'), ('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('laborious', 'JJ'), ('project', 'NN'), ('for', 'IN'), ('you', 'PRP')]\n",
            "4 - Remove Pronouns Before Verbs: [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('laborious', 'JJ'), ('project', 'NN'), ('for', 'IN'), ('you', 'PRP')]\n",
            "5 - Pronoun+Verb+Noun: [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('laborious', 'JJ'), ('project', 'NN'), ('for', 'IN'), ('you', 'PRP')]\n",
            "6 - Adjectives after Nouns: [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('project', 'NN'), ('laborious', 'JJ'), ('for', 'IN'), ('you', 'PRP')]\n",
            "7 - Add 'the': [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('project', 'NN'), ('laborious', 'JJ'), ('for', 'IN'), ('you', 'PRP')]\n",
            "8 - Attributive Nouns: [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('project', 'NN'), ('laborious', 'JJ'), ('for', 'IN'), ('you', 'PRP')]\n",
            "9 - Move not after verbs: [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('project', 'NN'), ('laborious', 'JJ'), ('for', 'IN'), ('you', 'PRP')]\n",
            "10 - TO/IN + PRP [('have', 'VBP'), ('finally', 'RB'), ('completed', 'VBN'), ('this', 'DT'), ('project', 'NN'), ('laborious', 'JJ'), ('for', 'IN'), ('you', 'PRP')]\n",
            "BEFORE: We have finally completed this laborious project for you\n",
            "AFTER: have finally completed this project laborious for you\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('have', 'VBP'),\n",
              " ('finally', 'RB'),\n",
              " ('completed', 'VBN'),\n",
              " ('this', 'DT'),\n",
              " ('project', 'NN'),\n",
              " ('laborious', 'JJ'),\n",
              " ('for', 'IN'),\n",
              " ('you', 'PRP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aviF68cKfrN0",
        "outputId": "644b2726-e833-434e-bfa5-20545f33ed30"
      },
      "source": [
        "spanglishMachine(\"finalmente terminó el proyecto difícil\")"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjectives before Nouns: [('finalmente', 'rg'), ('terminó', 'vmis3s0'), ('el', 'da0ms0'), ('difícil', 'aq0cs0'), ('proyecto', 'ncms000')]\n",
            "Attributive/Possesive Nouns: [('finalmente', 'rg'), ('terminó', 'vmis3s0'), ('el', 'da0ms0'), ('difícil', 'aq0cs0'), ('proyecto', 'ncms000')]\n",
            "BEFORE: finalmente terminó el proyecto difícil\n",
            "AFTER: finalmente ella terminó el difícil proyecto\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('finalmente', 'RB'),\n",
              " ('ella', 'PRP'),\n",
              " ('terminó', 'VBD'),\n",
              " ('el', 'DT'),\n",
              " ('difícil', 'JJ'),\n",
              " ('proyecto', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOUHd1fRgKSl",
        "outputId": "3e1a6e01-672c-4fff-b2d1-a75abddfcf13"
      },
      "source": [
        "sp.pos_tag(nltk.word_tokenize(\"Finalmente terminamos el proyecto difícil\")) #why Spanish --> English wasn't feasible"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Finalmente', 'rg'),\n",
              " ('terminamos', None),\n",
              " ('este', 'dd0ms0'),\n",
              " ('difícil', 'aq0cs0'),\n",
              " ('proyecto', 'ncms000')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G944WiS3dM82"
      },
      "source": [
        "## Stuff to Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drQ3Elk78cHp"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOSsb-duk_Ot",
        "outputId": "eb65e9f3-d848-4ccb-d9b1-d4fa22c4a02e"
      },
      "source": [
        "import spaghetti as sp\n",
        "import nltk\n",
        "nltk.download('cess_esp')\n",
        "mytagger = sp.CESSTagger()\n",
        "mytagger_uni = mytagger.uni\n",
        "mytagger_bi = mytagger.bi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gupDVPEVCNXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ed321b-c569-4ad1-ac8e-aa5f30aeab24"
      },
      "source": [
        "!pip install googletrans==3.1.0a0\n",
        "import googletrans\n",
        "print(googletrans.LANGUAGES)\n",
        "from googletrans import Translator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.7/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.4.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.5)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.22)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "{'af': 'afrikaans', 'sq': 'albanian', 'am': 'amharic', 'ar': 'arabic', 'hy': 'armenian', 'az': 'azerbaijani', 'eu': 'basque', 'be': 'belarusian', 'bn': 'bengali', 'bs': 'bosnian', 'bg': 'bulgarian', 'ca': 'catalan', 'ceb': 'cebuano', 'ny': 'chichewa', 'zh-cn': 'chinese (simplified)', 'zh-tw': 'chinese (traditional)', 'co': 'corsican', 'hr': 'croatian', 'cs': 'czech', 'da': 'danish', 'nl': 'dutch', 'en': 'english', 'eo': 'esperanto', 'et': 'estonian', 'tl': 'filipino', 'fi': 'finnish', 'fr': 'french', 'fy': 'frisian', 'gl': 'galician', 'ka': 'georgian', 'de': 'german', 'el': 'greek', 'gu': 'gujarati', 'ht': 'haitian creole', 'ha': 'hausa', 'haw': 'hawaiian', 'iw': 'hebrew', 'he': 'hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hu': 'hungarian', 'is': 'icelandic', 'ig': 'igbo', 'id': 'indonesian', 'ga': 'irish', 'it': 'italian', 'ja': 'japanese', 'jw': 'javanese', 'kn': 'kannada', 'kk': 'kazakh', 'km': 'khmer', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'lo': 'lao', 'la': 'latin', 'lv': 'latvian', 'lt': 'lithuanian', 'lb': 'luxembourgish', 'mk': 'macedonian', 'mg': 'malagasy', 'ms': 'malay', 'ml': 'malayalam', 'mt': 'maltese', 'mi': 'maori', 'mr': 'marathi', 'mn': 'mongolian', 'my': 'myanmar (burmese)', 'ne': 'nepali', 'no': 'norwegian', 'or': 'odia', 'ps': 'pashto', 'fa': 'persian', 'pl': 'polish', 'pt': 'portuguese', 'pa': 'punjabi', 'ro': 'romanian', 'ru': 'russian', 'sm': 'samoan', 'gd': 'scots gaelic', 'sr': 'serbian', 'st': 'sesotho', 'sn': 'shona', 'sd': 'sindhi', 'si': 'sinhala', 'sk': 'slovak', 'sl': 'slovenian', 'so': 'somali', 'es': 'spanish', 'su': 'sundanese', 'sw': 'swahili', 'sv': 'swedish', 'tg': 'tajik', 'ta': 'tamil', 'te': 'telugu', 'th': 'thai', 'tr': 'turkish', 'uk': 'ukrainian', 'ur': 'urdu', 'ug': 'uyghur', 'uz': 'uzbek', 'vi': 'vietnamese', 'cy': 'welsh', 'xh': 'xhosa', 'yi': 'yiddish', 'yo': 'yoruba', 'zu': 'zulu'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMZv6MloFg0y"
      },
      "source": [
        "translator = Translator(service_urls=['translate.googleapis.com'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kaAWdpZBqzq"
      },
      "source": [
        "## Spanglish Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60JXLI0rRHRD"
      },
      "source": [
        "def spanglishMachine(string): \n",
        "  origTokenized = nltk.word_tokenize(string)\n",
        "  translatedArray = \"\"\n",
        "  translatedString = \"\"\n",
        "  originalString = \"\"\n",
        "\n",
        "  #Use Google Translate to determine original language of input and feed input into either toSpanishStyle() or toEnglishStyle()\n",
        "  \n",
        "  translated = translator.translate(string, dest = \"en\") #initially translate to english\n",
        "  if translated.src == \"en\": #if the original language was english\n",
        "    tagged = nltk.pos_tag(origTokenized) #tag POS using nltk\n",
        "    originalString = \" \".join([word[0] for word in tagged]) #sentence for testing\n",
        "    #print(\"Original:\", tagged)\n",
        "\n",
        "    translatedArray = toSpanishStyle(tagged) #transfer to Spanish\n",
        "    translatedString = \" \".join([word[0] for word in translatedArray]) #sentence for testing\n",
        "    \n",
        "\n",
        "  else: #if original language was Spanish\n",
        "    tagged = sp.pos_tag(origTokenized) #tag POS using spaghetti\n",
        "    originalString = \" \".join([word[0] for word in tagged]) #sentence for testing\n",
        "    #print(\"Original:\", tagged)\n",
        "    translatedArray = changeSpanTags(toEnglishStyle(tagged)) #transfer to English\n",
        "    translatedString = \" \".join([word[0] for word in translatedArray])#sentence for testing\n",
        "\n",
        "  #print(\"after with tags:\", translatedArray)\n",
        "  print(\"BEFORE:\", originalString)\n",
        "  print(\"AFTER:\", translatedString)\n",
        "\n",
        "  return translatedArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSvhwFvaQEZL"
      },
      "source": [
        "## *English --> Spanish*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wB6cpEPmoc4",
        "outputId": "fa6a62cc-6b4f-459b-9e83-54e1f16d94e2"
      },
      "source": [
        "print(nltk.pos_tag(nltk.word_tokenize(\"my sister's day is not going well\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('my', 'PRP$'), ('sister', 'NN'), (\"'s\", 'POS'), ('day', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('going', 'VBG'), ('well', 'RB')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWvj4Ik8lHnw",
        "outputId": "836b46e9-a3ea-434d-b01c-09923252c304"
      },
      "source": [
        "spanglishMachine(\"My sister's day isn't going well\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - Posessive Nouns pt 1: [('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "2 - Long Sentence Verb+Noun: [('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "3 - Remove 'To' and Swap PRP: [('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "4 - Remove Pronouns Before Verbs: [('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "5 - Pronoun+Verb+Noun: [('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "6 - Adjectives after Nouns: [('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "7 - Add 'the': [('the', 'DT'), ('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "8 - Attributive Nouns: [('the', 'DT'), ('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('is', 'VBZ'), (\"n't\", 'RB'), ('going', 'VBG'), ('well', 'RB')]\n",
            "9 - Move not after verbs: [('the', 'DT'), ('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('not', 'RB'), ('is', 'VBZ'), ('going', 'VBG'), ('well', 'RB')]\n",
            "10 - TO/IN + PRP [('the', 'DT'), ('day', 'NN'), ('of', 'IN'), ('My', 'PRP$'), ('sister', 'NN'), ('not', 'RB'), ('is', 'VBZ'), ('going', 'VBG'), ('well', 'RB')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('day', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('My', 'PRP$'),\n",
              " ('sister', 'NN'),\n",
              " ('not', 'RB'),\n",
              " ('is', 'VBZ'),\n",
              " ('going', 'VBG'),\n",
              " ('well', 'RB')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyqcAIiut2OT"
      },
      "source": [
        "def toSpanishStyle(taggedWords):\n",
        "\n",
        "  #Rule 1: Move Possessive Nouns After What they Possess\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords)-1:\n",
        "    if taggedWords[idx][1] == \"POS\": #if current word is a possessive ending (\"'s\")\n",
        "      #possessive + noun and all its qualifiers\n",
        "      posNounEnd = idx-1\n",
        "      posNounStart = getNounStart(posNounEnd, taggedWords)\n",
        "      ownedNounStart = idx+1\n",
        "      ownedNounEnd = idx+2 #added 1 for the sake of indexing later\n",
        "      if idx+2 < len(taggedWords): #avoid runtime errors\n",
        "        if taggedWords[idx+2][1][:2] == \"NN\":\n",
        "          ownedNounEnd = idx+3\n",
        "          if idx+3 < len(taggedWords): #avoid runtime errors\n",
        "            if taggedWords[idx+3][1][:2] == \"NN\":\n",
        "              ownedNounEnd = idx+4\n",
        "      #move posNoun after ownedNoun\n",
        "      taggedWords[ownedNounEnd:ownedNounEnd] = nltk.pos_tag(nltk.word_tokenize(\"of\")) #insert \"of\" after owned noun\n",
        "      taggedWords[ownedNounEnd+1:ownedNounEnd+1] = taggedWords[posNounStart:posNounEnd+1] #add posessive noun stuff (minus 's) after owned noun stuff's \"of\"\n",
        "      del taggedWords[posNounStart:posNounEnd+2] #remove original pos noun stuff and pos\n",
        "\n",
        "      idx+=1 #so dont recount things\n",
        "    idx +=1\n",
        "  print(\"1 - Posessive Nouns pt 1:\", taggedWords)\n",
        "\n",
        "  #Rule 2: Noun after Verb When It's a Verb applied to the second noun in the Sentence (because switch more common with long sentences)\n",
        "  idx = 0\n",
        "  numSubjects = 0\n",
        "  while idx < len(taggedWords)-1:\n",
        "    if (taggedWords[idx][1][:2] == \"NN\") | (taggedWords[idx][1] == \"PRP\"): #if current word is a noun\n",
        "      if taggedWords[idx+1][1][:2] == \"VB\":        \n",
        "        numSubjects += 1\n",
        "        if numSubjects == 2: #if currently on second noun with verb\n",
        "          nounEnd = idx\n",
        "          nounStart = getNounStart(nounEnd, taggedWords) #where noun's qualifier's start\n",
        "          taggedWords[idx+1:idx+1] = taggedWords[nounStart:nounEnd+1] #add noun stuff after verb\n",
        "          del taggedWords[nounStart:nounEnd+1] #remove ealier noun elements\n",
        "    \n",
        "    idx += 1\n",
        "  print(\"2 - Long Sentence Verb+Noun:\", taggedWords)\n",
        "\n",
        "\n",
        "  #Rule 3: verb + pronoun1 + preposition + pronoun2 --> pronoun 2 + pronoun 1 + verb\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 3:\n",
        "    if taggedWords[idx][1][:2] == \"VB\": #if current word = verb\n",
        "      if (taggedWords[idx+1][1] == \"PRP\") & ((taggedWords[idx+2][1] == \"IN\") | (taggedWords[idx+2][1] == \"TO\")) & (taggedWords[idx+3][1] == \"PRP\"): #if PRP + IN + PRP\n",
        "        taggedWords[idx+1], taggedWords[idx+3] = taggedWords[idx+3], taggedWords[idx+1] #switch both pronouns\n",
        "        del taggedWords[idx+2] #delete IN\n",
        "        taggedWords[idx:idx] = taggedWords[idx+1:idx+3] #move both pronouns before the verb\n",
        "        del taggedWords[idx+3:idx+5] #delete the pronouns after the verb\n",
        "        idx+=1\n",
        "    idx+=1\n",
        "  print(\"3 - Remove 'To' and Swap PRP:\", taggedWords)\n",
        "\n",
        "  #Rule 4: Remove Pronouns Directly Before Conjugated Verbs If not 2 or 3 pronoun group before verb\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 1:\n",
        "    if taggedWords[idx][1] == \"PRP\": #if current word is a pronoun\n",
        "      if taggedWords[idx+1][1][:2] == \"VB\": #if word after is a verb\n",
        "        if idx-1 >= 0:\n",
        "          if taggedWords[idx-1][1] != \"PRP\": #if word before curerent word is not a pronoun\n",
        "            del taggedWords[idx] #remove the pronoun\n",
        "        else:\n",
        "          del taggedWords[idx] #if there is nothing before the pronoun at all, delete the pronoun\n",
        "    idx += 1\n",
        "  print(\"4 - Remove Pronouns Before Verbs:\", taggedWords)\n",
        "\n",
        "  #Rule 5: Noun + Verb + Pronoun --> Pronoun + Verb + Noun\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 1:\n",
        "    if taggedWords[idx][1][:2] == \"VB\": #if current word is a verb\n",
        "      #print(idx)\n",
        "      if taggedWords[idx+1][1] == \"PRP\": #if there's a pronoun directly after the verb\n",
        "        if idx-1 >= 0: #to avoid runtime errors\n",
        "          if taggedWords[idx-1][1][:2] == \"NN\": #if there's a noun right before the verb\n",
        "            nounEnd = idx # idx-1 + 1 for the sake of indexing later\n",
        "            nounStart = getNounStart(idx-1, taggedWords) #where noun's qualifier's start\n",
        "            if idx+2 < len(taggedWords):\n",
        "              if taggedWords[idx+2] == \"PRP\": #if there's a pronoun verb directly after it\n",
        "                taggedWords[idx-1] = taggedWords[idx+1:idx+3]\n",
        "                del taggedWords[idx+1:idx+3] #more both pronouns before verb\n",
        "              else:\n",
        "                taggedWords[idx], taggedWords[idx+1] = taggedWords[idx+1], taggedWords[idx] #swap pronoun and verb positions\n",
        "            else:\n",
        "              taggedWords[idx], taggedWords[idx+1] = taggedWords[idx+1], taggedWords[idx] #swap pronoun and verb positions\n",
        "            taggedWords[idx+2:idx+2] = taggedWords[nounStart:nounEnd] #add noun stuff after where pronoun used to be\n",
        "            del taggedWords[nounStart:nounEnd] #remove ealier noun elements\n",
        "            idx +=1 #so I don't recount verb\n",
        "    idx +=1\n",
        "  print(\"5 - Pronoun+Verb+Noun:\", taggedWords)\n",
        "\n",
        "  #Rule 6: Adjective + Noun --> Noun + Adjective\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 1: #for every tuple (word) in Array\n",
        "    if taggedWords[idx][1][:2] == \"JJ\": #if current word is an adjective (can tell general tag by first 2 letters of acronym)\n",
        "      if taggedWords[idx+1][1][:2] == \"NN\": #if the proceding word is a noun #how do I avoid an error if adjective is last word in list?\n",
        "        taggedWords[idx], taggedWords[idx+1] = taggedWords[idx+1], taggedWords[idx]\n",
        "        #idx += 1\n",
        "    idx += 1\n",
        "  print(\"6 - Adjectives after Nouns:\", taggedWords)\n",
        "\n",
        "  #Rule 7: \"The\" Before Every Non-Proper Noun\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords):\n",
        "    if (taggedWords[idx][1][:2] == \"NN\") & (taggedWords[idx][1][:3] != \"NNP\"): #if word is a noun and not a proper noun\n",
        "      if idx == 0:\n",
        "        taggedWords[idx:idx] = nltk.pos_tag(nltk.word_tokenize(\"the\"))\n",
        "        idx += 1 #so we don't recount nouns\n",
        "      else: #to avoid runtime errors\n",
        "        if (taggedWords[idx - 1][1] != \"DT\") & (taggedWords[idx - 1][1] != \"PRP$\") & (taggedWords[idx - 1][1][:2] != \"NN\"): #if noun doesn't already have an \"a\" or \"the\" in front of it and if it doesn't have another noun in front of it or a posessive pronouns like \"su\", waiting to be turned into noun+of+noun\n",
        "          taggedWords[idx:idx] = nltk.pos_tag(nltk.word_tokenize(\"the\"))\n",
        "          idx += 1 #so we don't recount nouns\n",
        "    idx += 1\n",
        "  print(\"7 - Add 'the':\", taggedWords)\n",
        "\n",
        "  #Rule 8: Attributive Nouns (coffee cup --> cup of coffee)\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 1:\n",
        "    if (taggedWords[idx][1][:2] == \"NN\") & (taggedWords[idx+1][1][:2] == \"NN\"): #if 2 nouns next to each other\n",
        "        taggedWords[idx], taggedWords[idx+1] = taggedWords[idx+1], taggedWords[idx] #swap the nouns\n",
        "        #print(taggedWords)\n",
        "        taggedWords[idx+1:idx+1] = nltk.pos_tag(nltk.word_tokenize(\"of\")) #insert \"of\" between the two nouns\n",
        "        #print(taggedWords)\n",
        "    idx += 1\n",
        "  print(\"8 - Attributive Nouns:\", taggedWords)\n",
        "\n",
        "  #Rule 9: If \"not\" or \"n't\" after verb, move \"not\" to before verb\n",
        "  nots = [i for i in taggedWords if (i == (\"n't\", \"RB\")) | (i == (\"not\", \"RB\"))] #array of all nots and n'ts\n",
        "  idx = 0\n",
        "  for i in nots:\n",
        "    idx = taggedWords.index(i, idx+1) #find index of tuple starting at next slot\n",
        "    if taggedWords[idx-1][1][:2] == \"VB\": #if the next word is a verb\n",
        "      taggedWords[idx] = (\"not\", \"RB\") #replace n't with not\n",
        "      taggedWords[idx], taggedWords[idx-1] = taggedWords[idx-1], taggedWords[idx] #switch verb and not\n",
        "  print(\"9 - Move not after verbs:\", taggedWords)\n",
        "\n",
        "  #Rule 10: VB + IN/TO + PRP --> PRP + VB\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords)-2:\n",
        "    if (taggedWords[idx][1][:2] == \"VB\") & ((taggedWords[idx+1][1] == \"IN\") | (taggedWords[idx+1][1] == \"TO\")) & (taggedWords[idx+2][1] == \"PRP\"): #VB + IN/TO + PRP\n",
        "      taggedWords[idx], taggedWords[idx+2] = taggedWords[idx+2], taggedWords[idx] #swap verb and pronoun\n",
        "      del taggedWords[idx+1] #delete IN\n",
        "      idx +=1\n",
        "    idx+= 1\n",
        "  print(\"10 - TO/IN + PRP\", taggedWords)\n",
        "\n",
        "\n",
        "  return(taggedWords)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ24BxdFuaLg"
      },
      "source": [
        "def getNounStart(endIndex, wordsArray):\n",
        "  nounStart = endIndex\n",
        "  while True:\n",
        "    if endIndex-1 >= 0: #to avoid runtime errors\n",
        "      if (wordsArray[endIndex-1][1][:2] == \"DT\") | (wordsArray[endIndex-1][1] == \"PRP$\") | (wordsArray[endIndex-1][1][:2] == \"POS\") | (wordsArray[endIndex-1][1][:2] == \"JJ\") | (wordsArray[endIndex-1][1][:2] == \"NN\"): #if there's a determiner or adjective next to the noun\n",
        "        nounStart = endIndex-1\n",
        "        if endIndex-2 >= 0: #to avoid runtime errors\n",
        "          if (wordsArray[endIndex-2][1][:2] == \"DT\") | (wordsArray[endIndex-2][1][:2] == \"PRP$\") | (wordsArray[endIndex-2][1][:2] == \"JJ\") | (wordsArray[endIndex-2][1][:2] == \"NN\"): #if there's a determiner next to the adjective\n",
        "            nounStart = endIndex-2\n",
        "            if endIndex-3 >=0:\n",
        "              if (wordsArray[endIndex-3][1][:2] == \"DT\") | (wordsArray[endIndex-3][1][:2] == \"PRP$\") | (wordsArray[endIndex-3][1][:2] == \"JJ\"): #if there's a determiner, pronoun, or possessive pronoun\n",
        "                nounStart = endIndex-3\n",
        "                if endIndex-4 >= 0:\n",
        "                  if (wordsArray[endIndex-4][1][:2] == \"DT\") | (wordsArray[endIndex-4][1][:2] == \"PRP$\"): #if there's a determiner or possessive pronoun\n",
        "                    nounStart = endIndex-4\n",
        "    \n",
        "    if nounStart-1 >= 0: #to avoid runtime errors\n",
        "      if wordsArray[nounStart-1][0] == \"of\":\n",
        "        endIndex = nounStart-1 #where noun's qualifier's start\n",
        "      else:\n",
        "        break\n",
        "    else:\n",
        "      break\n",
        "    #print(wordsArray[nounStart:endIndex+1])\n",
        "  return nounStart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne9tmi-0P7I2"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nZJ6VMCwta7",
        "outputId": "edabc1d1-49d9-4591-e6f2-1a4fc688480d"
      },
      "source": [
        "spanglishMachine(\"white coffee cup spilled him\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1 - Posessive Nouns pt 1: [('white', 'JJ'), ('coffee', 'NN'), ('cup', 'NN'), ('spilled', 'VBD'), ('him', 'PRP')]\n",
            "2 - Long Sentence Verb+Noun: [('white', 'JJ'), ('coffee', 'NN'), ('cup', 'NN'), ('spilled', 'VBD'), ('him', 'PRP')]\n",
            "Remove 'To' and Swap PRP: [('white', 'JJ'), ('coffee', 'NN'), ('cup', 'NN'), ('spilled', 'VBD'), ('him', 'PRP')]\n",
            "Remove Pronouns Before Verbs: [('white', 'JJ'), ('coffee', 'NN'), ('cup', 'NN'), ('spilled', 'VBD'), ('him', 'PRP')]\n",
            "Pronoun+Verb+Noun: [('him', 'PRP'), ('spilled', 'VBD'), ('white', 'JJ'), ('coffee', 'NN'), ('cup', 'NN')]\n",
            "6 - Adjectives after Nouns: [('him', 'PRP'), ('spilled', 'VBD'), ('coffee', 'NN'), ('cup', 'NN'), ('white', 'JJ')]\n",
            "7 - Add 'the': [('him', 'PRP'), ('spilled', 'VBD'), ('the', 'DT'), ('coffee', 'NN'), ('cup', 'NN'), ('white', 'JJ')]\n",
            "8 - Attributive Nouns: [('him', 'PRP'), ('spilled', 'VBD'), ('the', 'DT'), ('cup', 'NN'), ('of', 'IN'), ('coffee', 'NN'), ('white', 'JJ')]\n",
            "9 - Move not after verbs: [('him', 'PRP'), ('spilled', 'VBD'), ('the', 'DT'), ('cup', 'NN'), ('of', 'IN'), ('coffee', 'NN'), ('white', 'JJ')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('him', 'PRP'),\n",
              " ('spilled', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('cup', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('coffee', 'NN'),\n",
              " ('white', 'JJ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnV9pAZlq1Mc",
        "outputId": "4ff3dace-18d9-4117-b3f0-37c427aa4d75"
      },
      "source": [
        "spanglishMachine(\"Megan wrote it\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1 - Posessive Nouns pt 1: [('Megan', 'NNP'), ('wrote', 'VBD'), ('it', 'PRP')]\n",
            "2 - Long Sentence Verb+Noun: [('Megan', 'NNP'), ('wrote', 'VBD'), ('it', 'PRP')]\n",
            "Remove 'To' and Swap PRP: [('Megan', 'NNP'), ('wrote', 'VBD'), ('it', 'PRP')]\n",
            "Remove Pronouns Before Verbs: [('Megan', 'NNP'), ('wrote', 'VBD'), ('it', 'PRP')]\n",
            "Pronoun+Verb+Noun: [('it', 'PRP'), ('wrote', 'VBD'), ('Megan', 'NNP')]\n",
            "6 - Adjectives after Nouns: [('it', 'PRP'), ('wrote', 'VBD'), ('Megan', 'NNP')]\n",
            "7 - Add 'the': [('it', 'PRP'), ('wrote', 'VBD'), ('Megan', 'NNP')]\n",
            "8 - Attributive Nouns: [('it', 'PRP'), ('wrote', 'VBD'), ('Megan', 'NNP')]\n",
            "9 - Move not after verbs: [('it', 'PRP'), ('wrote', 'VBD'), ('Megan', 'NNP')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('it', 'PRP'), ('wrote', 'VBD'), ('Megan', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxtwzGXLwz9K",
        "outputId": "cf8039b1-8d36-4b66-b052-73b1d2133171"
      },
      "source": [
        "spanglishMachine(\"I write but the hot sun stays down\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1 - Posessive Nouns pt 1: [('I', 'PRP'), ('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('hot', 'JJ'), ('sun', 'NN'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "2 - Long Sentence Verb+Noun: [('I', 'PRP'), ('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('hot', 'JJ'), ('sun', 'NN'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "Remove 'To' and Swap PRP: [('I', 'PRP'), ('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('hot', 'JJ'), ('sun', 'NN'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "Remove Pronouns Before Verbs: [('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('hot', 'JJ'), ('sun', 'NN'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "Pronoun+Verb+Noun: [('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('hot', 'JJ'), ('sun', 'NN'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "6 - Adjectives after Nouns: [('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('sun', 'NN'), ('hot', 'JJ'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "7 - Add 'the': [('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('sun', 'NN'), ('hot', 'JJ'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "8 - Attributive Nouns: [('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('sun', 'NN'), ('hot', 'JJ'), ('stays', 'VBZ'), ('down', 'RP')]\n",
            "9 - Move not after verbs: [('write', 'VBP'), ('but', 'CC'), ('the', 'DT'), ('sun', 'NN'), ('hot', 'JJ'), ('stays', 'VBZ'), ('down', 'RP')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('write', 'VBP'),\n",
              " ('but', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('sun', 'NN'),\n",
              " ('hot', 'JJ'),\n",
              " ('stays', 'VBZ'),\n",
              " ('down', 'RP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI0PEOKPUDmr",
        "outputId": "2d8cfb0b-1f93-4c07-9277-e10e8bb204db"
      },
      "source": [
        "spanglishMachine(\"I wrote while the blue wolf cried to the moon\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1 - Posessive Nouns pt 1: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('blue', 'JJ'), ('wolf', 'NN'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "2 - Long Sentence Verb+Noun: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('blue', 'JJ'), ('wolf', 'NN'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "Remove 'To' and Swap PRP: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('blue', 'JJ'), ('wolf', 'NN'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "Remove Pronouns Before Verbs: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('blue', 'JJ'), ('wolf', 'NN'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "Pronoun+Verb+Noun: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('blue', 'JJ'), ('wolf', 'NN'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "6 - Adjectives after Nouns: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('wolf', 'NN'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "7 - Add 'the': [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('wolf', 'NN'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "8 - Attributive Nouns: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('wolf', 'NN'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "9 - Move not after verbs: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('wolf', 'NN'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wrote', 'VBD'),\n",
              " ('while', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('wolf', 'NN'),\n",
              " ('blue', 'JJ'),\n",
              " ('cried', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('moon', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XZXbCINXg6a",
        "outputId": "e19894ed-b18c-41c0-ecff-504bfd71e6ae"
      },
      "source": [
        "spanglishMachine(\"I wrote while blue coffee cups cried to the moon\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1 - Posessive Nouns pt 1: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "2 - Long Sentence Verb+Noun: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "Remove 'To' and Swap PRP: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "Remove Pronouns Before Verbs: [('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "Pronoun+Verb+Noun: [('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "6 - Adjectives after Nouns: [('wrote', 'VBD'), ('while', 'IN'), ('coffee', 'NN'), ('cups', 'NNS'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "7 - Add 'the': [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('coffee', 'NN'), ('cups', 'NNS'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "8 - Attributive Nouns: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('cups', 'NNS'), ('of', 'IN'), ('coffee', 'NN'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n",
            "9 - Move not after verbs: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('cups', 'NNS'), ('of', 'IN'), ('coffee', 'NN'), ('blue', 'JJ'), ('cried', 'VBD'), ('to', 'TO'), ('the', 'DT'), ('moon', 'NN')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wrote', 'VBD'),\n",
              " ('while', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('cups', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('coffee', 'NN'),\n",
              " ('blue', 'JJ'),\n",
              " ('cried', 'VBD'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('moon', 'NN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TdJQd4o_tw3",
        "outputId": "43dfed80-4baf-459f-bce2-c6ba1d78bba7"
      },
      "source": [
        "spanglishMachine(\"blue sister's heart cried\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "owned noun start:  3 owned noun end:  4\n",
            "[('blue', 'JJ'), ('sister', 'NN'), (\"'s\", 'POS'), ('heart', 'NN'), ('of', 'IN'), ('cried', 'VBD')]\n",
            "[('blue', 'JJ'), ('sister', 'NN'), (\"'s\", 'POS'), ('heart', 'NN'), ('of', 'IN'), ('blue', 'JJ'), ('sister', 'NN'), ('cried', 'VBD')]\n",
            " 1 - Posessive Nouns pt 1: [('heart', 'NN'), ('of', 'IN'), ('blue', 'JJ'), ('sister', 'NN'), ('cried', 'VBD')]\n",
            "2 - Long Sentence Verb+Noun: [('heart', 'NN'), ('of', 'IN'), ('blue', 'JJ'), ('sister', 'NN'), ('cried', 'VBD')]\n",
            "Remove 'To' and Swap PRP: [('heart', 'NN'), ('of', 'IN'), ('blue', 'JJ'), ('sister', 'NN'), ('cried', 'VBD')]\n",
            "Remove Pronouns Before Verbs: [('heart', 'NN'), ('of', 'IN'), ('blue', 'JJ'), ('sister', 'NN'), ('cried', 'VBD')]\n",
            "Pronoun+Verb+Noun: [('heart', 'NN'), ('of', 'IN'), ('blue', 'JJ'), ('sister', 'NN'), ('cried', 'VBD')]\n",
            "6 - Adjectives after Nouns: [('heart', 'NN'), ('of', 'IN'), ('sister', 'NN'), ('blue', 'JJ'), ('cried', 'VBD')]\n",
            "7 - Add 'the': [('the', 'DT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sister', 'NN'), ('blue', 'JJ'), ('cried', 'VBD')]\n",
            "8 - Attributive Nouns: [('the', 'DT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sister', 'NN'), ('blue', 'JJ'), ('cried', 'VBD')]\n",
            "9 - Move not after verbs: [('the', 'DT'), ('heart', 'NN'), ('of', 'IN'), ('the', 'DT'), ('sister', 'NN'), ('blue', 'JJ'), ('cried', 'VBD')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 'DT'),\n",
              " ('heart', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('sister', 'NN'),\n",
              " ('blue', 'JJ'),\n",
              " ('cried', 'VBD')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie8Rxo-oBvmW",
        "outputId": "ed8cf274-e21f-42a3-fe23-b9c3442f43b2"
      },
      "source": [
        "spanglishMachine(\"I wrote while Joanna's blue coffee cups cried to it\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('coffee', 'NN')\n",
            "('cups', 'NNS')\n",
            " 1 - Posessive Nouns pt 1: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "[]\n",
            "2 - Long Sentence Verb+Noun: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "3 - Remove 'To' and Swap PRP: [('I', 'PRP'), ('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "4 - Remove Pronouns Before Verbs: [('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "Pronoun+Verb+Noun: [('wrote', 'VBD'), ('while', 'IN'), ('blue', 'JJ'), ('coffee', 'NN'), ('cups', 'NNS'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "6 - Adjectives after Nouns: [('wrote', 'VBD'), ('while', 'IN'), ('coffee', 'NN'), ('cups', 'NNS'), ('blue', 'JJ'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "7 - Add 'the': [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('coffee', 'NN'), ('cups', 'NNS'), ('blue', 'JJ'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "8 - Attributive Nouns: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('cups', 'NNS'), ('of', 'IN'), ('coffee', 'NN'), ('blue', 'JJ'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "9 - Move not after verbs: [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('cups', 'NNS'), ('of', 'IN'), ('coffee', 'NN'), ('blue', 'JJ'), ('of', 'IN'), ('Joanna', 'NNP'), ('cried', 'VBD'), ('to', 'TO'), ('it', 'PRP')]\n",
            "10 - TO/IN + PRP [('wrote', 'VBD'), ('while', 'IN'), ('the', 'DT'), ('cups', 'NNS'), ('of', 'IN'), ('coffee', 'NN'), ('blue', 'JJ'), ('of', 'IN'), ('Joanna', 'NNP'), ('it', 'PRP'), ('cried', 'VBD')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wrote', 'VBD'),\n",
              " ('while', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('cups', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('coffee', 'NN'),\n",
              " ('blue', 'JJ'),\n",
              " ('of', 'IN'),\n",
              " ('Joanna', 'NNP'),\n",
              " ('it', 'PRP'),\n",
              " ('cried', 'VBD')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ads14dBgYnn",
        "outputId": "374644ef-4429-4cea-c075-6ba823b2fcd9"
      },
      "source": [
        "spanglishMachine(\"she wrote it to him\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1 - Posessive Nouns pt 1: [('she', 'PRP'), ('wrote', 'VBD'), ('it', 'PRP'), ('to', 'TO'), ('him', 'PRP')]\n",
            "2 - Long Sentence Verb+Noun: [('she', 'PRP'), ('wrote', 'VBD'), ('it', 'PRP'), ('to', 'TO'), ('him', 'PRP')]\n",
            "Remove 'To' and Swap PRP: [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n",
            "Remove Pronouns Before Verbs: [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n",
            "Pronoun+Verb+Noun: [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n",
            "6 - Adjectives after Nouns: [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n",
            "7 - Add 'the': [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n",
            "8 - Attributive Nouns: [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n",
            "9 - Move not after verbs: [('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('she', 'PRP'), ('him', 'PRP'), ('it', 'PRP'), ('wrote', 'VBD')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDJ0b90IagIm",
        "outputId": "18e660cf-db84-43af-de0a-e3cab25061d2"
      },
      "source": [
        "print(nltk.pos_tag(nltk.word_tokenize((\"the too of\"))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 'DT'), ('too', 'RB'), ('of', 'IN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVqny7dyQMyX"
      },
      "source": [
        "## Spanish --> English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ll1gteCt_KZ"
      },
      "source": [
        "def toEnglishStyle(taggedWords):\n",
        "  #Rule 1: Noun + Adjective --> Adjective + Noun\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 1: #for every tuple (word) in Array\n",
        "    if taggedWords[idx][1][0] == \"n\": #if current word is an noun\n",
        "      if taggedWords[idx+1][1][:2] == \"aq\": #if the proceding word is a adjective\n",
        "        taggedWords[idx], taggedWords[idx+1] = taggedWords[idx+1], taggedWords[idx]\n",
        "    idx += 1\n",
        "  print(\"Adjectives before Nouns:\", taggedWords)\n",
        "\n",
        "  #Rule 2: attributive nouns (2nd noun = improper) and posessive nouns (2nd noun = proper)\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords) - 2: #for every tuple (word) in Array\n",
        "    if taggedWords[idx][1][0] == \"n\": #if current word is an improper noun\n",
        "      if taggedWords[idx+1][0] == \"de\": #if the proceding word is \"de\"\n",
        "        if taggedWords[idx+2][1][:2] == \"nc\": #if the next word is an improper noun -- ATTRIBUTIVE NOUN\n",
        "          taggedWords[idx], taggedWords[idx+2] = taggedWords[idx+2], taggedWords[idx] #swap 1st and 2nd nouns\n",
        "          del taggedWords[idx+1] #delete \"de\"\n",
        "        elif taggedWords[idx+2][1][:2] == \"np\": #if 2nd noun = proper --> POSSESSIVE NOUN\n",
        "          taggedWords[idx], taggedWords[idx+2] = taggedWords[idx+2], taggedWords[idx] #swap nouns\n",
        "          taggedWords[idx+1:idx+2] = [(\"'de\", \"POS\")]\n",
        "    idx += 1\n",
        "  print(\"Attributive/Possesive Nouns:\", taggedWords)\n",
        "\n",
        "  #Rule 3: add pronouns to front of subject-less verbs\n",
        "  idx = 0\n",
        "  while idx < len(taggedWords): #for every tuple (word) in Array\n",
        "    if taggedWords[idx][1][:2] == \"vm\":\n",
        "      if (idx-1 < 0) | (taggedWords[idx-1][1][0] != \"n\"):\n",
        "        if taggedWords[idx][1][4] == \"1\": #1st person\n",
        "          if taggedWords[idx][1][5] == \"s\": #singular\n",
        "            taggedWords[idx:idx] = [(\"yo\", \"PRP\")]\n",
        "          else: #plural\n",
        "            taggedWords[idx:idx] = [(\"nosotros\", \"PRP\")]\n",
        "        elif taggedWords[idx][1][4] == \"3\": #3rd person\n",
        "          if taggedWords[idx][1][5] == \"s\": #singular\n",
        "            rand = (random.randint(0,9) < 5)\n",
        "            if rand == True:\n",
        "              taggedWords[idx:idx] = [(\"ella\", \"PRP\")] #Choose gender of pronoun randomly\n",
        "            else:\n",
        "              taggedWords[idx:idx] = [(\"él\", \"PRP\")]\n",
        "          else: #plural\n",
        "            if rand == True: \n",
        "              taggedWords[idx:idx] = [(\"ellas\", \"PRP\")]\n",
        "            else:\n",
        "              taggedWords[idx:idx] = [(\"ellos\", \"PRP\")]\n",
        "        else: #2nd person\n",
        "          if taggedWords[idx][1][5] == \"s\": #singular\n",
        "            taggedWords[idx:idx] = [(\"tu\", \"PRP\")]\n",
        "          else:\n",
        "            taggedWords[idx:idx] = [(\"vosotros\", \"PRP\")]  \n",
        "      \n",
        "        idx += 1\n",
        "    \n",
        "    idx += 1\n",
        "\n",
        "    \n",
        "  #omit la from beginning of plural direct objects\n",
        "\n",
        "  return taggedWords"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x59qB5jawHs"
      },
      "source": [
        "def changeSpanTags(taggedArray): #translating spaghetti POS codes to NLTK codes to potentially make syntax trees\n",
        "  idx = 0\n",
        "  while idx < len(taggedArray):\n",
        "    tag = \"\"\n",
        "\n",
        "    #Nouns#\n",
        "    if taggedArray[idx][1][0] == \"n\":\n",
        "      tag += \"NN\"\n",
        "      if taggedArray[idx][1][1] == \"p\": #proper\n",
        "        tag += \"P\"\n",
        "      if taggedArray[idx][1][4] == \"p\": #plural\n",
        "        tag += \"S\"\n",
        "\n",
        "    #Adjectives#\n",
        "    elif taggedArray[idx][1][:2] == \"aq\":\n",
        "      tag += \"JJ\"\n",
        "    \n",
        "    #Determiner#\n",
        "    elif (taggedArray[idx][1][:2] == \"da\") | (taggedArray[idx][1][:2] == \"dd\"):\n",
        "      tag += \"DT\"\n",
        "      \n",
        "    #Predeterminer#\n",
        "    elif (taggedArray[idx][1][:2] == \"di\") | (taggedArray[idx][1][:2] == \"dn\"):\n",
        "      tag += \"DT\"\n",
        "\n",
        "    #Prounouns#\n",
        "    elif taggedArray[idx][1][0] == \"p\": #quien and quienes are weird??\n",
        "      tag += \"PRP\"\n",
        "\n",
        "    elif taggedArray[idx][1][:2] == \"dp\":\n",
        "      tag += \"PRP$\"\n",
        "\n",
        "    #Adverbs#\n",
        "    elif taggedArray[idx][1][:2] == \"rg\":\n",
        "      tag += \"RB\"\n",
        "\n",
        "    #Verbs#\n",
        "    elif taggedArray[idx][1][:2] == \"vm\":\n",
        "      tag += \"VB\"\n",
        "      if taggedArray[idx][1][2] == \"n\": #infinitive\n",
        "        tag\n",
        "      elif taggedArray[idx][1][2] == \"g\": #gerand/present participle\n",
        "        tag += \"G\"\n",
        "      elif taggedArray[idx][1][2] == \"p\":\n",
        "        tag += \"N\"\n",
        "      elif taggedArray[idx][1][2] == \"i\": #conjugated\n",
        "        if taggedArray[idx][1][3] == \"p\": #present tense\n",
        "          if taggedArray[idx][1][4:6] == \"3s\":\n",
        "            tag += \"Z\"\n",
        "          else:\n",
        "            tag += \"P\"\n",
        "        elif (taggedArray[idx][1][3] == \"s\") | (taggedArray[idx][1][3] == \"i\"): #preterite vs. imperfect --> past\n",
        "          tag += \"D\"\n",
        "\n",
        "    #Coordinating Conjunctions#\n",
        "    elif taggedArray[idx][1][:2] == \"cc\":\n",
        "      tag += \"CC\"\n",
        "\n",
        "    #Prepositions#\n",
        "    elif (taggedArray[idx][1][:3] == \"sps\") | (taggedArray[idx][1][:2] == \"cs\"):\n",
        "      tag += \"IN\"\n",
        "\n",
        "    else:\n",
        "      tag += taggedArray[idx][1]\n",
        "  \n",
        "    taggedArray[idx] = (taggedArray[idx][0], tag)\n",
        "    idx += 1\n",
        "\n",
        "  return taggedArray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IQ2NE-KQmvj"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axYtC-o7DZ7G"
      },
      "source": [
        "**Notes**\n",
        "* Spaghetti tagger doesn't know people names\n",
        "* Its grammar is also wrong surrounding adjectives... doesn't perceive blancos as an adjective (sees it as noun) but percieves blanco as adjective, even when paired with perros\n",
        "* nor does it keep track of verbs conjugated in first person?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM2qSIHEIOid",
        "outputId": "46009f44-17d7-4070-ee73-adabdac79d76"
      },
      "source": [
        "spanglishMachine(\"una chica bonita corre\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjectives before Nouns: [('una', 'di0fs0'), ('bonita', 'aq0fs0'), ('chica', 'ncfs000'), ('corre', 'vmip3s0')]\n",
            "Attributive/Possesive Nouns: [('una', 'di0fs0'), ('bonita', 'aq0fs0'), ('chica', 'ncfs000'), ('corre', 'vmip3s0')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('una', 'DT'), ('bonita', 'JJ'), ('chica', 'NN'), ('corre', 'VBZ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXyqCICjHPR1",
        "outputId": "07fd2893-80f3-4bee-803a-8c350bffa2f4"
      },
      "source": [
        "spanglishMachine(\"café de Argentina\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjectives before Nouns: [('café', 'ncms000'), ('de', 'sps00'), ('Argentina', 'np0000l')]\n",
            "Attributive/Possesive Nouns: [('Argentina', 'np0000l'), (\"'de\", 'POS'), ('café', 'ncms000')]\n",
            "after: Argentina 'de café\n",
            "after with tags: [('Argentina', 'NNP'), (\"'de\", 'POS'), ('café', 'NN')]\n",
            "before: café de Argentina\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTwUFZWH2Ki4",
        "outputId": "e4c5d9f8-205e-41da-c78d-807a6fdafdeb"
      },
      "source": [
        "spanglishMachine(\"taza de café\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjectives before Nouns: [('taza', 'ncfs000'), ('de', 'sps00'), ('café', 'ncms000')]\n",
            "Attributive/Possesive Nouns: [('café', 'ncms000'), ('taza', 'ncfs000')]\n",
            "after: café taza\n",
            "after with tags: [('café', 'NN'), ('taza', 'NN')]\n",
            "before: taza de café\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o8IwxHwrUpm",
        "outputId": "fdebafb6-c079-4b65-aafd-5a531fa5ff23"
      },
      "source": [
        "spanglishMachine(\"corre\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjectives before Nouns: [('corre', 'vmip3s0')]\n",
            "Attributive/Possesive Nouns: [('corre', 'vmip3s0')]\n",
            "after: él corre\n",
            "after with tags: [('él', 'PRP'), ('corre', 'VBZ')]\n",
            "before: corre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K_RFVdjEsS6"
      },
      "source": [
        "**Parsing POS Code Meaning**\n",
        "\n",
        "<u>Nouns</u>\n",
        "\n",
        "[0:2]\n",
        "* nc = regular noun\n",
        "* np = proper noun\n",
        "\n",
        "[3]\n",
        "* f = feminine\n",
        "* m = masculine\n",
        "\n",
        "[4]\n",
        "* s = singular\n",
        "* p = plural\n",
        "\n",
        "<u>Adjectives</u>\n",
        "\n",
        "[0:2] = aq\n",
        "\n",
        "[3]\n",
        "* f = feminine\n",
        "* m = masculine\n",
        "* c = gender nuetral\n",
        "\n",
        "[4]\n",
        "* s = singular\n",
        "* theoretically, p = plural, but spaghetti tagger doesn't seem to have many plural adjectives logged\n",
        "\n",
        "<u>Pronouns</u>\n",
        "\n",
        "[:2] = pp\n",
        "\n",
        "[2] = # = person (1st vs 3rd)\n",
        "\n",
        "[3]\n",
        "* m = masculine\n",
        "* f = feminine\n",
        "\n",
        "[4]\n",
        "* s = singular\n",
        "* p = plural\n",
        "\n",
        "<u>Possessive Pronounns</u>\n",
        "('nuestra', 'dp1fsp')\n",
        "\n",
        "[:2] = dp\n",
        "\n",
        "[2] = 1-3 person\n",
        "\n",
        "[3] = masc or fem\n",
        "\n",
        "[5] = fem or masc\n",
        "\n",
        "<u>Determiners</u>\n",
        "\n",
        "[0] = d\n",
        "\n",
        "[1]\n",
        "* a = el, la, los, las\n",
        "* i = un, una, unos, unas\n",
        "* d = esos, esta\n",
        "\n",
        "[2]\n",
        "* 0 = standard\n",
        "* 3 = possessive\n",
        "\n",
        "[3]\n",
        "* f = feminine\n",
        "* m = masculine\n",
        "\n",
        "[4]\n",
        "* s = singular\n",
        "* f = feminine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT5CjHjPQjR5"
      },
      "source": [
        "## Research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRiyEVEOMikU"
      },
      "source": [
        "[nltk Acronym Meanings](https://www.guru99.com/pos-tagging-chunking-nltk.html#:~:text=POS%20Tagging%20(Parts%20of%20Speech,is%20also%20called%20grammatical%20tagging.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO9DQu_L_EvG"
      },
      "source": [
        "[Grammar Diff Btwn Spanish and English](https://www.thoughtco.com/grammatical-differences-between-spanish-and-english-4119326#:~:text=Word%20order%20is%20less%20fixed,subjunctive%20mood%20than%20English%20does.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA82S6sS5K_F"
      },
      "source": [
        "***Sometimes Pronouns Come Before Verbs and Nouns After***\n",
        "\n",
        "Lo escribió Cervantes.\n",
        "*   Megan wrote it (the book) --> It (the book) wrote Cervantes\n",
        "*   NNP VBD PRP --> PRP VBD NNP\n",
        "\n",
        "\"No recuerdo el momento en que salió Pablo\"\n",
        "*   I don't remember the moment in which Pablo left --> I don't remember the moment in which left Pablo\n",
        "*   (PRP VBP RB VB DT NN IN WDT) NNP VBD --> (same) VBD NNP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCp1Ijm678FV"
      },
      "source": [
        "***Spanish Uses Double Negatives***\n",
        "\n",
        "* Apenas come. (She barely eats.)\n",
        "* Apenas come nada. (She barely eats anything --> she barely eats nothing)\n",
        "* No tengo ninguno. (I don't have any --> I don't have none)\n",
        "* Nadie sabe eso. (Nobody knows that.)\n",
        "* Jamás fumo. (I never smoke.)\n",
        "* Tampoco comió. (She didn't eat either.)\n",
        "* Tampoco comió nada. (She didn't eat anything either --> She didn't eat nothing either)\n",
        "* No habló. (He didn't speak.)\n",
        "* No dijo nada. (He said nothing --> He didn't say nothing)\n",
        "* No le dijo nada a nadie. (He didn't say anything to anybody --> He didn't say nothing to nobody)\n",
        "* No compro ninguno. (I'm not buying any --> I'm not buying none)\n",
        "* Nunca le compra nada a nadie. (She never buys anything for anybody --> She never buy nothing for nobody)\n",
        "* No come ni siquiera pan. (He doesn't even eat bread --> He doesnt --honestly I don't even know how to translate this literally)\n",
        "* Ni siquiera come pan. (He doesn't even eat bread.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cNVR48c9tA0"
      },
      "source": [
        "***Can Omit Pronouns if Verb is Conjugated***\n",
        "\n",
        "* No compro ninguno. (I'm not buying any --> I'm not buying none)\n",
        "* Nunca le compra nada a nadie. (She never buys anything for anybody --> She never buy nothing for nobody)\n",
        "* No come ni siquiera pan. (He doesn't even eat bread --> He doesnt --honestly I don't even know how to translate this literally)\n",
        "* Ni siquiera come pan. (He doesn't even eat bread.)\n",
        "\n",
        "*Especially* Don't need \"I\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AASQ8qUr-lRI"
      },
      "source": [
        "***Attributive Nouns***\n",
        "Not coffee cup --> taza para cafe --> cup of coffee\n",
        "\n",
        "if two nouns next to each other --> switch nouns and add \"of\" (para/de) between\n",
        "\n",
        "* In some cases, this is accomplished by Spanish having adjectival forms that don't exist in English. For example, informático can be the equivalent of \"computer\" as an adjective, so a computer table is a mesa informática."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYO7dHT41p_s"
      },
      "source": [
        "***Tacking Pronouns to End of Verbs When \"To\"***\n",
        " * darmelo = give it to me --> give me it\n",
        " * escribamostelo = let's write it to you --> let's write you it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4yH_HBz0BZf"
      },
      "source": [
        "## **English Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJG4occ7x8Tb",
        "outputId": "73e3bec1-fccd-4fa2-c8ba-a5fd3ca4fa68"
      },
      "source": [
        "nltk.download(\"popular\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-kpFQz7J6uA"
      },
      "source": [
        "## **Spanish Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaDbFAtkOmKZ"
      },
      "source": [
        "# Read the corpus into a list, \n",
        "# each entry in the list is one sentence.\n",
        "cess_sents = cess.tagged_sents()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBtEmt7FPZ8i"
      },
      "source": [
        "# Train the unigram tagger\n",
        "uni_tag = ut(cess_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEGYFga6P4No"
      },
      "source": [
        "spanishSentence = \"las chicas bonitas corrion\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_tyHxvV1zBY",
        "outputId": "e99c450c-8dc5-4fed-da77-ae205df1b5d9"
      },
      "source": [
        "#tokenized = spanishSentence.split()\n",
        "tokenized = nltk.word_tokenize(spanishSentence)\n",
        "print(tokenized)\n",
        "tagged1 = sp.pos_tag(tokenized)\n",
        "print(tagged1)\n",
        "tagged2 = mytagger_uni.tag(tokenized)\n",
        "print(tagged2)\n",
        "tagged4 = mytagger_bi.tag(tokenized)\n",
        "print(tagged4)\n",
        "print(tagged4[0])\n",
        "print(tagged4[0][0]) #How to parce through intervals of the tuple in the array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['las', 'chicas', 'bonitas', 'corrion']\n",
            "[('las', 'da0fp0'), ('chicas', 'ncfp000'), ('bonitas', None), ('corrion', None)]\n",
            "[('las', 'da0fp0'), ('chicas', 'ncfp000'), ('bonitas', None), ('corrion', None)]\n",
            "[('las', 'da0fp0'), ('chicas', 'ncfp000'), ('bonitas', None), ('corrion', None)]\n",
            "('las', 'da0fp0')\n",
            "las\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7iAKLsWdED2"
      },
      "source": [
        "## **Syntax** **trees**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFvVZ0c9k2mE"
      },
      "source": [
        "import os\n",
        "import matplotlib as mpl\n",
        "if os.environ.get('DISPLAY','') == '':\n",
        "    print('no display found. Using non-interactive Agg backend')\n",
        "    mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzqAOhi6lQug",
        "outputId": "05c289e1-bac0-4d6e-ee76-b80c9f91fdc1"
      },
      "source": [
        "### CREATE VIRTUAL DISPLAY ###\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Ign:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8\n",
            "Err:1 http://security.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8\n",
            "  404  Not Found [IP: 91.189.88.142 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.8_amd64.deb  404  Not Found [IP: 91.189.88.142 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_PeZhw_i_Mj",
        "outputId": "ef68648f-5bcd-4557-fc6b-81af0754775d"
      },
      "source": [
        "# EXTRA STUFF TO DISPLAY NLTK SYNTAX TREES #  \n",
        "%matplotlib inline\n",
        "### INSTALL GHOSTSCRIPT ) ###\n",
        "!apt install ghostscript python3-tk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ghostscript is already the newest version (9.26~dfsg+0-0ubuntu0.18.04.14).\n",
            "python3-tk is already the newest version (3.6.9-1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "lP1mbYPsfyfG",
        "outputId": "3d6d68ee-cdbd-41b2-d3ff-8bf4e5a74989"
      },
      "source": [
        "chunked_sentence = '(S (NP this tree) (VP (V is) (AdjP pretty)))'\n",
        "\n",
        "from nltk.tree import Tree\n",
        "from IPython.display import display\n",
        "tree = Tree.fromstring(str(chunked_sentence))\n",
        "display(tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0m_canvas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mwidget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_to_treesegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/draw/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, **kw)\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# If no parent was given, set up a top-level window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-p>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: couldn't connect to display \":1.0\""
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('NP', ['this', 'tree']), Tree('VP', [Tree('V', ['is']), Tree('AdjP', ['pretty'])])])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g-Y9HWMycIR",
        "outputId": "f9aa8886-5011-4ef6-b1ad-6520e070ae67"
      },
      "source": [
        "Sentence = \"The white dog ran\"\n",
        "tokenized = nltk.word_tokenize(Sentence)\n",
        "print(tokenized)\n",
        "tagged = nltk.pos_tag(tokenized)\n",
        "print(tagged)\n",
        "chunkGram = r\"\"\"Chunk: {<DT\\w?>*<JJ\\w?>}\"\"\" #creating a chunk\n",
        "chunkParser = nltk.RegexpParser(chunkGram) #parsing the chunk\n",
        "#chunked = chunkParser.parse(tagged)\n",
        "for tree in chunkParser.parse(tagged): #creates a syntax tree for the parsed chunk\n",
        "    print(tree)\n",
        "    #tree.draw()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'white', 'dog', 'ran']\n",
            "[('The', 'DT'), ('white', 'JJ'), ('dog', 'NN'), ('ran', 'VBD')]\n",
            "(Chunk The/DT white/JJ)\n",
            "('dog', 'NN')\n",
            "('ran', 'VBD')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-95_ks94yZr",
        "outputId": "27a39db2-3585-4507-9c30-7db407cfbfee"
      },
      "source": [
        "Sentence = \"white the ran dog.\"\n",
        "tokenized = nltk.word_tokenize(Sentence)\n",
        "print(tokenized)\n",
        "tagged = nltk.pos_tag(tokenized)\n",
        "print(tagged)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['white', 'the', 'ran', 'dog', '.']\n",
            "[('white', 'JJ'), ('the', 'DT'), ('ran', 'NN'), ('dog', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0AR8EKfCHbP"
      },
      "source": [
        "## **Sanskrit Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1IRb82_D-Cd"
      },
      "source": [
        "Mounting Drive and importing text files of Sanskrit texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvEDZkqnEK-R",
        "outputId": "cebce4f4-ec09-4855-8b7d-315cfff243fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqsUhQPYCObp"
      },
      "source": [
        "gItA = open(\"/content/drive/MyDrive/Colab Notebooks/ Final Project/Colab Notebooks/bhagavadgItA.txt\",\"r\")\n",
        "meghadhUta = open(\"/content/drive/MyDrive/Colab Notebooks/ Final Project/Colab Notebooks/meghadUta.txt\",\"r\")\n",
        "rAmAyaNa = open(\"/content/drive/MyDrive/Colab Notebooks/ Final Project/Colab Notebooks/rAmAyaNa.txt\", \"r\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "snXpa2v0F_9D",
        "outputId": "2b15ed1b-3c47-4e86-f73d-67b8d43ec2f4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-b5768a72344c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pos/hmm/make -f makefile-osx\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv8b6SgbHmJa"
      },
      "source": [
        "comment to delete later: trying to figure out how to use repository here : https://github.com/ad2476/pos-research which has a sanskrit tagger. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcPj9dYhsxH3"
      },
      "source": [
        "## PYCHARM CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThEBL-XEs0Wv"
      },
      "source": [
        "##Import necessary tools##\n",
        "import os\n",
        "import sys\n",
        "import numpy\n",
        "import IPython\n",
        "from IPython import display\n",
        "import nltk\n",
        "\n",
        "nltk.download('popular')\n",
        "import sys\n",
        "import pygame\n",
        "from pygame.locals import *\n",
        "import googletrans\n",
        "from googletrans import Translator\n",
        "\n",
        "# translator = Translator(service_urls=['translate.googleapis.com'])\n",
        "translator = Translator()\n",
        "import geopandas\n",
        "import spaghetti as sp\n",
        "\n",
        "# making sure ghostscript works correctly so we can correctly convert .ps to .png for syntax tree\n",
        "os.environ[\"PATH\"] += \"Library/usr/local/bin\"\n",
        "os.environ[\"PATH\"] = \"/usr/local/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"PATH\"] = \"Library/usr/local/bin:\" + os.environ[\"PATH\"]\n",
        "\n",
        "# initialize user input of english sentence\n",
        "userSentence = input(\"Please enter a sentence under 13 words:\\n\")\n",
        "print(type(userSentence))\n",
        "\n",
        "\n",
        "###SPANGLISH MACHINE###\n",
        "\n",
        "# Find where nouns begin\n",
        "def getNounStart(endIndex, wordsArray):\n",
        "    nounStart = endIndex\n",
        "    while True:\n",
        "        if endIndex - 1 >= 0:  # to avoid runtime errors\n",
        "            if (wordsArray[endIndex - 1][1][:2] == \"DT\") | (wordsArray[endIndex - 1][1] == \"PRP$\") | (\n",
        "                    wordsArray[endIndex - 1][1][:2] == \"POS\") | (wordsArray[endIndex - 1][1][:2] == \"JJ\") | (\n",
        "                    wordsArray[endIndex - 1][1][:2] == \"NN\"):  # if there's a determiner or adjective next to the noun\n",
        "                nounStart = endIndex - 1\n",
        "                if endIndex - 2 >= 0:  # to avoid runtime errors\n",
        "                    if (wordsArray[endIndex - 2][1][:2] == \"DT\") | (wordsArray[endIndex - 2][1][:2] == \"PRP$\") | (\n",
        "                            wordsArray[endIndex - 2][1][:2] == \"JJ\") | (\n",
        "                            wordsArray[endIndex - 2][1][:2] == \"NN\"):  # if there's a determiner next to the adjective\n",
        "                        nounStart = endIndex - 2\n",
        "                        if endIndex - 3 >= 0:\n",
        "                            if (wordsArray[endIndex - 3][1][:2] == \"DT\") | (\n",
        "                                    wordsArray[endIndex - 3][1][:2] == \"PRP$\") | (wordsArray[endIndex - 3][1][\n",
        "                                                                                  :2] == \"JJ\"):  # if there's a determiner, pronoun, or possessive pronoun\n",
        "                                nounStart = endIndex - 3\n",
        "                                if endIndex - 4 >= 0:\n",
        "                                    if (wordsArray[endIndex - 4][1][:2] == \"DT\") | (wordsArray[endIndex - 4][1][\n",
        "                                                                                    :2] == \"PRP$\"):  # if there's a determiner or possessive pronoun\n",
        "                                        nounStart = endIndex - 4\n",
        "\n",
        "        if nounStart - 1 >= 0:  # to avoid runtime errors\n",
        "            if wordsArray[nounStart - 1][0] == \"of\":\n",
        "                endIndex = nounStart - 1  # where noun's qualifier's start\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "        # print(wordsArray[nounStart:endIndex+1])\n",
        "    return nounStart\n",
        "\n",
        "# Switch to spanish style (implement Spanish syntax rule)\n",
        "def toSpanishStyle(taggedWords):\n",
        "    # Rule 1: Move Possessive Nouns After What they Possess\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 1:\n",
        "        if taggedWords[idx][1] == \"POS\":  # if current word is a possessive ending (\"'s\")\n",
        "            # possessive + noun and all its qualifiers\n",
        "            posNounEnd = idx - 1\n",
        "            posNounStart = getNounStart(posNounEnd, taggedWords)\n",
        "            ownedNounStart = idx + 1\n",
        "            ownedNounEnd = idx + 2  # added 1 for the sake of indexing later\n",
        "            if idx + 2 < len(taggedWords):  # avoid runtime errors\n",
        "                if taggedWords[idx + 2][1][:2] == \"NN\":\n",
        "                    ownedNounEnd = idx + 3\n",
        "                    if idx + 3 < len(taggedWords):  # avoid runtime errors\n",
        "                        if taggedWords[idx + 3][1][:2] == \"NN\":\n",
        "                            ownedNounEnd = idx + 4\n",
        "            # move posNoun after ownedNoun\n",
        "            taggedWords[ownedNounEnd:ownedNounEnd] = nltk.pos_tag(\n",
        "                nltk.word_tokenize(\"of\"))  # insert \"of\" after owned noun\n",
        "            taggedWords[ownedNounEnd + 1:ownedNounEnd + 1] = taggedWords[\n",
        "                                                             posNounStart:posNounEnd + 1]  # add posessive noun stuff (minus 's) after owned noun stuff's \"of\"\n",
        "            del taggedWords[posNounStart:posNounEnd + 2]  # remove original pos noun stuff and pos\n",
        "\n",
        "            idx += 1  # so dont recount things\n",
        "        idx += 1\n",
        "    print(\"1 - Posessive Nouns pt 1:\", taggedWords)\n",
        "\n",
        "    # Rule 2: Noun after Verb When It's a Verb applied to the second noun in the Sentence (because switch more common with long sentences)\n",
        "    idx = 0\n",
        "    numSubjects = 0\n",
        "    while idx < len(taggedWords) - 1:\n",
        "        if (taggedWords[idx][1][:2] == \"NN\") | (taggedWords[idx][1] == \"PRP\"):  # if current word is a noun\n",
        "            if taggedWords[idx + 1][1][:2] == \"VB\":\n",
        "                numSubjects += 1\n",
        "                if numSubjects == 2:  # if currently on second noun with verb\n",
        "                    nounEnd = idx\n",
        "                    nounStart = getNounStart(nounEnd, taggedWords)  # where noun's qualifier's start\n",
        "                    taggedWords[idx + 1:idx + 1] = taggedWords[nounStart:nounEnd + 1]  # add noun stuff after verb\n",
        "                    del taggedWords[nounStart:nounEnd + 1]  # remove ealier noun elements\n",
        "\n",
        "        idx += 1\n",
        "    print(\"2 - Long Sentence Verb+Noun:\", taggedWords)\n",
        "\n",
        "    # Rule 3: verb + pronoun1 + preposition + pronoun2 --> pronoun 2 + pronoun 1 + verb\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 3:\n",
        "        if taggedWords[idx][1][:2] == \"VB\":  # if current word = verb\n",
        "            if (taggedWords[idx + 1][1] == \"PRP\") & (\n",
        "                    (taggedWords[idx + 2][1] == \"IN\") | (taggedWords[idx + 2][1] == \"TO\")) & (\n",
        "                    taggedWords[idx + 3][1] == \"PRP\"):  # if PRP + IN + PRP\n",
        "                taggedWords[idx + 1], taggedWords[idx + 3] = taggedWords[idx + 3], taggedWords[\n",
        "                    idx + 1]  # switch both pronouns\n",
        "                del taggedWords[idx + 2]  # delete IN\n",
        "                taggedWords[idx:idx] = taggedWords[idx + 1:idx + 3]  # move both pronouns before the verb\n",
        "                del taggedWords[idx + 3:idx + 5]  # delete the pronouns after the verb\n",
        "                idx += 1\n",
        "        idx += 1\n",
        "    print(\"3 - Remove 'To' and Swap PRP:\", taggedWords)\n",
        "\n",
        "    # Rule 4: Remove Pronouns Directly Before Conjugated Verbs If not 2 or 3 pronoun group before verb\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 1:\n",
        "        if taggedWords[idx][1] == \"PRP\":  # if current word is a pronoun\n",
        "            if taggedWords[idx + 1][1][:2] == \"VB\":  # if word after is a verb\n",
        "                if idx - 1 >= 0:\n",
        "                    if taggedWords[idx - 1][1] != \"PRP\":  # if word before curerent word is not a pronoun\n",
        "                        del taggedWords[idx]  # remove the pronoun\n",
        "                else:\n",
        "                    del taggedWords[idx]  # if there is nothing before the pronoun at all, delete the pronoun\n",
        "        idx += 1\n",
        "    print(\"4 - Remove Pronouns Before Verbs:\", taggedWords)\n",
        "\n",
        "    # Rule 5: Noun + Verb + Pronoun --> Pronoun + Verb + Noun\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 1:\n",
        "        if taggedWords[idx][1][:2] == \"VB\":  # if current word is a verb\n",
        "            # print(idx)\n",
        "            if taggedWords[idx + 1][1] == \"PRP\":  # if there's a pronoun directly after the verb\n",
        "                if idx - 1 >= 0:  # to avoid runtime errors\n",
        "                    if taggedWords[idx - 1][1][:2] == \"NN\":  # if there's a noun right before the verb\n",
        "                        nounEnd = idx  # idx-1 + 1 for the sake of indexing later\n",
        "                        nounStart = getNounStart(idx - 1, taggedWords)  # where noun's qualifier's start\n",
        "                        if idx + 2 < len(taggedWords):\n",
        "                            if taggedWords[idx + 2] == \"PRP\":  # if there's a pronoun verb directly after it\n",
        "                                taggedWords[idx - 1] = taggedWords[idx + 1:idx + 3]\n",
        "                                del taggedWords[idx + 1:idx + 3]  # more both pronouns before verb\n",
        "                            else:\n",
        "                                taggedWords[idx], taggedWords[idx + 1] = taggedWords[idx + 1], taggedWords[\n",
        "                                    idx]  # swap pronoun and verb positions\n",
        "                        else:\n",
        "                            taggedWords[idx], taggedWords[idx + 1] = taggedWords[idx + 1], taggedWords[\n",
        "                                idx]  # swap pronoun and verb positions\n",
        "                        taggedWords[idx + 2:idx + 2] = taggedWords[\n",
        "                                                       nounStart:nounEnd]  # add noun stuff after where pronoun used to be\n",
        "                        del taggedWords[nounStart:nounEnd]  # remove ealier noun elements\n",
        "                        idx += 1  # so I don't recount verb\n",
        "        idx += 1\n",
        "    print(\"5 - Pronoun+Verb+Noun:\", taggedWords)\n",
        "\n",
        "    # Rule 6: Adjective + Noun --> Noun + Adjective\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 1:  # for every tuple (word) in Array\n",
        "        if taggedWords[idx][1][\n",
        "           :2] == \"JJ\":  # if current word is an adjective (can tell general tag by first 2 letters of acronym)\n",
        "            if taggedWords[idx + 1][1][\n",
        "               :2] == \"NN\":  # if the proceding word is a noun #how do I avoid an error if adjective is last word in list?\n",
        "                taggedWords[idx], taggedWords[idx + 1] = taggedWords[idx + 1], taggedWords[idx]\n",
        "                # idx += 1\n",
        "        idx += 1\n",
        "    print(\"6 - Adjectives after Nouns:\", taggedWords)\n",
        "\n",
        "    # Rule 7: \"The\" Before Every Non-Proper Noun\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords):\n",
        "        if (taggedWords[idx][1][:2] == \"NN\") & (\n",
        "                taggedWords[idx][1][:3] != \"NNP\"):  # if word is a noun and not a proper noun\n",
        "            if idx == 0:\n",
        "                taggedWords[idx:idx] = nltk.pos_tag(nltk.word_tokenize(\"the\"))\n",
        "                idx += 1  # so we don't recount nouns\n",
        "            else:  # to avoid runtime errors\n",
        "                if (taggedWords[idx - 1][1] != \"DT\") & (taggedWords[idx - 1][1] != \"PRP$\") & (taggedWords[idx - 1][1][\n",
        "                                                                                              :2] != \"NN\"):  # if noun doesn't already have an \"a\" or \"the\" in front of it and if it doesn't have another noun in front of it or a posessive pronouns like \"su\", waiting to be turned into noun+of+noun\n",
        "                    taggedWords[idx:idx] = nltk.pos_tag(nltk.word_tokenize(\"the\"))\n",
        "                    idx += 1  # so we don't recount nouns\n",
        "        idx += 1\n",
        "    print(\"7 - Add 'the':\", taggedWords)\n",
        "\n",
        "    # Rule 8: Attributive Nouns (coffee cup --> cup of coffee)\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 1:\n",
        "        if (taggedWords[idx][1][:2] == \"NN\") & (taggedWords[idx + 1][1][:2] == \"NN\"):  # if 2 nouns next to each other\n",
        "            taggedWords[idx], taggedWords[idx + 1] = taggedWords[idx + 1], taggedWords[idx]  # swap the nouns\n",
        "            # print(taggedWords)\n",
        "            taggedWords[idx + 1:idx + 1] = nltk.pos_tag(nltk.word_tokenize(\"of\"))  # insert \"of\" between the two nouns\n",
        "            # print(taggedWords)\n",
        "        idx += 1\n",
        "    print(\"8 - Attributive Nouns:\", taggedWords)\n",
        "\n",
        "    # Rule 9: If \"not\" or \"n't\" after verb, move \"not\" to before verb\n",
        "    nots = [i for i in taggedWords if (i == (\"n't\", \"RB\")) | (i == (\"not\", \"RB\"))]  # array of all nots and n'ts\n",
        "    idx = 0\n",
        "    for i in nots:\n",
        "        idx = taggedWords.index(i, idx + 1)  # find index of tuple starting at next slot\n",
        "        if taggedWords[idx - 1][1][:2] == \"VB\":  # if the next word is a verb\n",
        "            taggedWords[idx] = (\"not\", \"RB\")  # replace n't with not\n",
        "            taggedWords[idx], taggedWords[idx - 1] = taggedWords[idx - 1], taggedWords[idx]  # switch verb and not\n",
        "    print(\"9 - Move not after verbs:\", taggedWords)\n",
        "\n",
        "    # Rule 10: VB + IN/TO + PRP --> PRP + VB\n",
        "    idx = 0\n",
        "    while idx < len(taggedWords) - 2:\n",
        "        if (taggedWords[idx][1][:2] == \"VB\") & (\n",
        "                (taggedWords[idx + 1][1] == \"IN\") | (taggedWords[idx + 1][1] == \"TO\")) & (\n",
        "                taggedWords[idx + 2][1] == \"PRP\"):  # VB + IN/TO + PRP\n",
        "            taggedWords[idx], taggedWords[idx + 2] = taggedWords[idx + 2], taggedWords[idx]  # swap verb and pronoun\n",
        "            del taggedWords[idx + 1]  # delete IN\n",
        "            idx += 1\n",
        "        idx += 1\n",
        "    print(\"10 - TO/IN + PRP\", taggedWords)\n",
        "\n",
        "    return (taggedWords)\n",
        "\n",
        "\n",
        "# main spanglish machine function\n",
        "def spanglishMachine(string):\n",
        "    origTokenized = nltk.word_tokenize(string)\n",
        "    translatedArray = \"\"\n",
        "    translatedString = \"\"\n",
        "    originalString = \"\"\n",
        "\n",
        "    # Use Google Translate to determine original language of input and feed input into either toSpanishStyle() or toEnglishStyle()\n",
        "\n",
        "    translated = translator.translate(string, dest=\"en\")  # initially translate to english\n",
        "    if translated.src == \"en\":  # if the original language was english\n",
        "        tagged = nltk.pos_tag(origTokenized)  # tag POS using nltk\n",
        "        originalString = \" \".join([word[0] for word in tagged]) #sentence for testing\n",
        "        # print(\"Original:\", tagged)\n",
        "\n",
        "        translatedArray = toSpanishStyle(tagged)  # transfer to Spanish\n",
        "        translatedString = \" \".join([word[0] for word in translatedArray]) #sentence for testing\n",
        "\n",
        "# Commented out the Spanish as source language because spaghetti is difficult on computer python. Go to colab!\n",
        "    #else:  # if original language was Spanish\n",
        "     #   tagged = sp.pos_tag(origTokenized)  # tag POS using spaghetti\n",
        "      #  originalString = \" \".join([word[0] for word in tagged]) #sentence for testing\n",
        "        # print(\"Original:\", tagged)\n",
        "      #  translatedArray = changeSpanTags(toEnglishStyle(tagged))  # transfer to English\n",
        "      #  translatedString = \" \".join([word[0] for word in translatedArray])#sentence for testing\n",
        "\n",
        "        # print(\"after:\", translatedString)\n",
        "        # print(\"after with tags:\", translatedArray)\n",
        "        # print(\"before:\", originalString)\n",
        "\n",
        "    # Convert original sentence to text file\n",
        "    file = open('translated_sentence.txt', \"w\")\n",
        "    file.write(f'{translatedString}\\n')\n",
        "    file.close()\n",
        "\n",
        "    # Convert sentence with Spanish syntax to text file\n",
        "    file2 = open(f'original_sentence.txt', \"w\")\n",
        "    file2.write(f'{originalString}\\n')\n",
        "    file2.close()\n",
        "\n",
        "    return translatedArray\n",
        "\n",
        "\n",
        "spanglishMachine(userSentence)  # calls spanglishMachine with user-inputed sentence\n",
        "\n",
        "\n",
        "#  SYNTAX TREES: creates syntax trees that displays chunks for English and Spanglish###\n",
        "def syntaxTreeGenerator(array):  # makes syntax tree for original sentence\n",
        "    for item in array:\n",
        "        tokenized = nltk.word_tokenize(item)  # create list that separates each word as its own entry\n",
        "        tagged = nltk.pos_tag(tokenized)  # creates tuple with the word and its POS tag\n",
        "\n",
        "        chunkGram = r\"\"\"Chunk: {<JJ\\w?>*<NN\\w?>|<NNP>*<POS>*<JJ\\w?>*<NN\\w?>|<NN\\w?>*<VB\\w?>|<NN\\w?>*<VB\\w?>*<PRP>|<NN>*<NN>}\"\"\"  # defining the chunks for the chunk parser\n",
        "        chunkParser = nltk.RegexpParser(chunkGram)  # parsing the chunks\n",
        "\n",
        "        chunked = chunkParser.parse(tagged)  # applying the chunk parser to the tagged words of the array\n",
        "\n",
        "        print(chunked)\n",
        "\n",
        "\n",
        "    # Save syntax tree as .ps file\n",
        "    from nltk.draw.tree import TreeView\n",
        "    TreeView(chunked)._cframe.print_to_file('/Users/catherine/PycharmProjects/CLPS0950FinalProject/tree.ps')\n",
        "\n",
        "    # Convert .ps file to .png\n",
        "    from PIL import Image\n",
        "    psimage = Image.open(r'/Users/catherine/PycharmProjects/CLPS0950FinalProject/tree.ps')\n",
        "    psimage.save(r'/Users/catherine/PycharmProjects/CLPS0950FinalProject/pygame_tree.png')\n",
        "\n",
        "\n",
        "def spanglishSyntaxTreeGenerator(array):  # makes syntax tree for Spanglish sentence\n",
        "    array = spanglishMachine(userSentence)  # feeds in the output of the spanglishMachine\n",
        "\n",
        "    chunkGram = r\"\"\"Chunk: {<NN\\w?>*<JJ\\w?>|<NN\\w?>*<IN>*<NNP>*<JJ\\w?>|<NN\\w?>*<JJ\\w?>*<IN>*<NNP>|<PRP>*<VB?>*<NN>|<NN\\w?>*<IN>*<NN\\w?>}\"\"\"  # defining the chunks for the chunk parser\n",
        "    chunkParser = nltk.RegexpParser(chunkGram)  # parsing the chunk\n",
        "\n",
        "    chunked = chunkParser.parse(array) # applying the chunk parser to the Spanglish sentence, which is already tagged\n",
        "    print(chunked)\n",
        "\n",
        "    # Save syntax tree as .ps file\n",
        "    from nltk.draw.tree import TreeView\n",
        "    TreeView(chunked)._cframe.print_to_file('/Users/catherine/PycharmProjects/CLPS0950FinalProject/spanglish_tree.ps')\n",
        "\n",
        "    # Convert .ps file to .png\n",
        "    from PIL import Image\n",
        "    psimage = Image.open(r'/Users/catherine/PycharmProjects/CLPS0950FinalProject/spanglish_tree.ps')\n",
        "    psimage.save(r'/Users/catherine/PycharmProjects/CLPS0950FinalProject/pygame_spanglish_tree.png')\n",
        "\n",
        "# call both syntax tree functions\n",
        "syntaxTreeGenerator([userSentence])\n",
        "spanglishSyntaxTreeGenerator([userSentence])\n",
        "\n",
        "# determine how far right the syntax trees and sentences will be in pygame based on sentence length\n",
        "distright = 750 - len(userSentence) * 5\n",
        "\n",
        "# initialize display window for pygame\n",
        "pygame.init()\n",
        "width, height = 1400, 720\n",
        "screen = pygame.display.set_mode((width, height))\n",
        "\n",
        "# define colors\n",
        "black = (0, 0, 0)\n",
        "white = (255, 255, 255)\n",
        "\n",
        "# pygame window name\n",
        "pygame.display.set_caption('Spanglish Generator')\n",
        "\n",
        "# fonts\n",
        "font = pygame.font.Font('freesansbold.ttf', 32)\n",
        "font2 = pygame.font.Font('freesansbold.ttf', 20)\n",
        "\n",
        "# text surface object and text blocks\n",
        "titleText = font.render('Spanglish Generator', True, black, white)\n",
        "textRect = titleText.get_rect()\n",
        "\n",
        "syntaxTreeText = font2.render('Original Sentence Syntax Tree', True, black, white)\n",
        "rectSyntaxTreeText = syntaxTreeText.get_rect()\n",
        "\n",
        "spanglishSyntaxTreeText = font2.render('Spanglish Sentence Syntax Tree', True, black, white)\n",
        "rectSpanglishSyntaxTreeText = spanglishSyntaxTreeText.get_rect()\n",
        "\n",
        "originalSentenceText = font2.render('Original Sentence:', True, black, white)\n",
        "rectOriginalSentenceText = originalSentenceText.get_rect()\n",
        "\n",
        "spanglishSentenceText = font2.render('Spanglish Sentence:', True, black, white)\n",
        "rectSpanglishSentenceText = spanglishSentenceText.get_rect()\n",
        "\n",
        "# load images (background, syntax trees, pos tag list)\n",
        "background = pygame.image.load(\"/Users/catherine/Desktop/project_background.png\")\n",
        "syntaxTree = pygame.image.load(\"/Users/catherine/PycharmProjects/CLPS0950FinalProject/pygame_tree.png\")\n",
        "rectSyntaxTree = syntaxTree.get_rect()\n",
        "screen_rect = screen.get_rect()\n",
        "spanglishSyntaxTree = pygame.image.load(\n",
        "    \"/Users/catherine/PycharmProjects/CLPS0950FinalProject/pygame_spanglish_tree.png\")\n",
        "rectSpanglishSyntaxTree = spanglishSyntaxTree.get_rect()\n",
        "posTagList = pygame.image.load(\"/Users/catherine/PycharmProjects/CLPS0950FinalProject/pos_tag_list.png\")\n",
        "\n",
        "# Read in the text from the text files saved from spanglishMachine function and assign size and color variables\n",
        "line_text = open(\"translated_sentence.txt\", \"rt\").readlines()\n",
        "line_text2 = open(\"original_sentence.txt\", \"rt\").readlines()\n",
        "\n",
        "WIDTH = 600\n",
        "HEIGHT = 500\n",
        "WHITE = 255, 255, 255\n",
        "BLUE = 0, 0, 200\n",
        "\n",
        "\n",
        "# infinite loop for pygame window\n",
        "while True:\n",
        "    # allow user to exit screen\n",
        "    for event in pygame.event.get():\n",
        "        # check if event is the X button\n",
        "        if event.type == pygame.QUIT:\n",
        "            # if yes then quite game\n",
        "            pygame.quit()\n",
        "            sys.exit()\n",
        "    # clear the screen before putting things in again\n",
        "    screen.fill(white)\n",
        "\n",
        "    # draw screen elements\n",
        "    for x in range(width // background.get_width() + int(1)):\n",
        "        for y in range(height // background.get_height() + int(1)):\n",
        "            screen.blit(background, (x * 100, y * 100)) # draws screen background\n",
        "    screen.blit(titleText, titleText.get_rect(midtop=screen_rect.midtop))  # says syntax generator at top of screen\n",
        "    screen.blit(originalSentenceText, (distright, 70)) # says Original Sentence\n",
        "    screen.blit(spanglishSentenceText, (distright, 400)) # Says Spanglish Sentence\n",
        "    screen.blit(syntaxTreeText, (distright, 140)) # says Original Sentence Syntax Tree\n",
        "    screen.blit(spanglishSyntaxTreeText, (distright, 470)) # says Spanglish Sentence Syntax Tree\n",
        "    screen.blit(syntaxTree, (distright, 170)) # draws original syntax tree, moves left if longer\n",
        "    screen.blit(spanglishSyntaxTree, (distright, 500)) # draws Spanglish syntax tree, moves left if longer\n",
        "    screen.blit(posTagList, (30, 30)) # draws pos tag list\n",
        "\n",
        "\n",
        "# Gets text from the .txt files of the original and Spanglish sentences to showup on pygame window\n",
        "    def textRender(screen, text, x, y, the_font, colour=(128, 128, 128), justification=\"left\"):\n",
        "        justification = justification[0].upper()\n",
        "        max_width = 0\n",
        "        text_bitmaps = []\n",
        "        # Convert the text to bitmaps, calculate the justification width\n",
        "        for t in text:\n",
        "            text_bitmap = the_font.render(t, True, colour)\n",
        "            text_width = text_bitmap.get_width()\n",
        "            text_bitmaps.append((text_width, text_bitmap))\n",
        "            if (max_width < text_width):\n",
        "                max_width = text_width\n",
        "        # Paint all the text bitmaps to the screen with justification\n",
        "        for (width, bitmap) in text_bitmaps:\n",
        "            xpos = x\n",
        "            width_diff = max_width - width\n",
        "            if (justification == 'R'):  # right-justify\n",
        "                xpos = x + width_diff\n",
        "            elif (justification == 'C'):  # centre-justify\n",
        "                xpos = x + (width_diff // 2)\n",
        "            screen.blit(bitmap, (xpos, y))\n",
        "            y += bitmap.get_height()\n",
        "\n",
        "\n",
        "    # Create font for the text read through textRender\n",
        "    font3 = pygame.font.Font(None, 30)\n",
        "    # three copies of the same text, different justificaiton\n",
        "    textRender(screen, line_text2, distright, 100, font3, BLUE)\n",
        "    textRender(screen, line_text, distright, 430, font3, BLUE)\n",
        "\n",
        "    # Update the screen\n",
        "    pygame.display.flip()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}